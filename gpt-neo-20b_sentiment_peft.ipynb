{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# coding=utf-8\n", "# Copyright 2022 The HuggingFace Inc. team. All rights reserved.\n", "#\n", "# Licensed under the Apache License, Version 2.0 (the \"License\");\n", "# you may not use this file except in compliance with the License.\n", "# You may obtain a copy of the License at\n", "#\n", "#     http://www.apache.org/licenses/LICENSE-2.0\n", "#\n", "# Unless required by applicable law or agreed to in writing, software\n", "# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n", "# See the License for the specific language governing permissions and\n", "# limitations under the License.\n", "from dataclasses import dataclass, field\n", "from typing import Optional"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from datasets import load_dataset\n", "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training\n", "from tqdm import tqdm\n", "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, pipeline"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n", "from trl.core import LengthSampler"]}, {"cell_type": "markdown", "metadata": {}, "source": ["######################################################################<br>\n", "This is a fully working simple example to use trl with accelerate.<br>\n", "<br>\n", "This example fine-tunes a GPT2 model on the IMDB dataset using PPO<br>\n", "(proximal policy optimization).<br>\n", "in any of the following settings (with the same script):<br>\n", "  - single CPU or single GPU<br>\n", "  - fp16 (mixed-precision) or fp32 (normal precision)<br>\n", "<br>\n", "To run it in each of these various modes, first initialize the accelerate<br>\n", "configuration with `accelerate config`<br>\n", "<br>\n", "######################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["######################################################################<br>\n", "NOTE for to train with a 8-bit model a more recent version of<br>\n", "transformers is required, full dependecies for this example:<br>\n", "pip install  bitsandbytes datasets accelerate loralib<br>\n", "pip install  git+https://github.com/huggingface/transformers.git@main<br>\n", "pip install peft<br>\n", "######################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We first define the configuration of the experiment, defining the model, the dataset,<br>\n", "the training parameters, and the PPO parameters.<br>\n", "Check the default arguments in the `PPOConfig` class for more details.<br>\n", "If you want to log with tensorboard, add the kwarg<br>\n", "`project_kwargs={\"logging_dir\": PATH_TO_LOGS}` to the PPOConfig."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define and parse arguments."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@dataclass\n", "class ScriptArguments:\n", "    \"\"\"\n", "    The name of the Casual LM model we wish to fine with PPO\n", "    \"\"\"\n\n", "    # NOTE: gpt2 models use Conv1D instead of Linear layers which are not yet supported in 8 bit mode\n", "    # models like gpt-neo* models are more suitable.\n", "    model_name: Optional[str] = field(\n", "        default=\"edbeeching/gpt-neo-125M-imdb-lora-adapter-merged\", metadata={\"help\": \"the model name\"}\n", "    )\n", "    log_with: Optional[str] = field(default=None, metadata={\"help\": \"use 'wandb' to log with wandb\"})\n", "    learning_rate: Optional[float] = field(default=1.41e-5, metadata={\"help\": \"the learning rate\"})\n", "    mini_batch_size: Optional[int] = field(default=16, metadata={\"help\": \"the PPO minibatch size\"})\n", "    batch_size: Optional[int] = field(default=256, metadata={\"help\": \"the batch size\"})\n", "    gradient_accumulation_steps: Optional[int] = field(\n", "        default=1, metadata={\"help\": \"the number of gradient accumulation steps\"}\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parser = HfArgumentParser(ScriptArguments)\n", "script_args = parser.parse_args_into_dataclasses()[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["config = PPOConfig(\n", "    model_name=script_args.model_name,\n", "    learning_rate=script_args.learning_rate,\n", "    log_with=script_args.log_with,\n", "    mini_batch_size=script_args.mini_batch_size,\n", "    batch_size=script_args.batch_size,\n", "    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We then define the arguments to pass to the sentiment analysis pipeline.<br>\n", "We set `return_all_scores` to True to get the sentiment score for each token."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": config.mini_batch_size}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Below is an example function to build the dataset. In our case, we use the IMDB dataset<br>\n", "from the `datasets` library. One should customize this function to train the model on<br>\n", "its own dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_dataset(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n", "    \"\"\"\n", "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n", "    customize this function to train the model on its own dataset.\n", "    Args:\n", "        dataset_name (`str`):\n", "            The name of the dataset to be loaded.\n", "    Returns:\n", "        dataloader (`torch.utils.data.DataLoader`):\n", "            The dataloader for the dataset.\n", "    \"\"\"\n", "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n", "    tokenizer.pad_token = tokenizer.eos_token\n", "    # load imdb with datasets\n", "    ds = load_dataset(dataset_name, split=\"train\")\n", "    ds = ds.rename_columns({\"text\": \"review\"})\n", "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n", "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n", "    def tokenize(sample):\n", "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n", "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n", "        return sample\n", "    ds = ds.map(tokenize, batched=False)\n", "    ds.set_format(type=\"torch\")\n", "    return ds"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We retrieve the dataloader by calling the `build_dataset` function."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset = build_dataset(config)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def collator(data):\n", "    return dict((key, [d[key] for d in data]) for key in data[0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["set seed before initializing value head for deterministic eval"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["set_seed(config.seed)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's build the model, the reference model, and the tokenizer."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pretrained_model = AutoModelForCausalLM.from_pretrained(config.model_name, load_in_8bit=True, device_map=\"auto\")\n", "tokenizer = AutoTokenizer.from_pretrained(config.model_name)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n### Apply LoRA<br>\n", "Here comes the magic with `peft`! Let's load a `PeftModel` and specify that we are going to use low-rank adapters (LoRA) using `get_peft_model` utility function from `peft`.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def print_trainable_parameters(model):\n", "    \"\"\"\n", "    Prints the number of trainable parameters in the model.\n", "    \"\"\"\n", "    trainable_params = 0\n", "    all_param = 0\n", "    for _, param in model.named_parameters():\n", "        all_param += param.numel()\n", "        if param.requires_grad:\n", "            trainable_params += param.numel()\n", "    print(\n", "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["target_modules = None\n", "if \"gpt-neox\" in script_args.model_name:\n", "    target_modules = [\"query_key_value\", \"xxx\"]  # workaround to use 8bit training on this model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lora_config = LoraConfig(\n", "    r=16,\n", "    lora_alpha=32,\n", "    target_modules=target_modules,  # handled automatically by peft\n", "    lora_dropout=0.05,\n", "    bias=\"none\",\n", "    task_type=\"CAUSAL_LM\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pretrained_model = prepare_model_for_int8_training(pretrained_model, output_embedding_layer_name=\"embed_out\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["hacky workaround due to issues with \"EleutherAI/gpt-neox-20b\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if \"gpt-neox\" in script_args.model_name:\n", "    for name, param in pretrained_model.named_parameters():\n", "        # freeze base model's layers\n", "        param.requires_grad = False\n", "        if getattr(pretrained_model, \"is_loaded_in_8bit\", False):\n", "            # cast layer norm in fp32 for stability for 8bit models\n", "            if param.ndim == 1 and \"layer_norm\" in name:\n", "                param.data = param.data.to(torch.float16)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pretrained_model = get_peft_model(pretrained_model, lora_config)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = AutoModelForCausalLMWithValueHead.from_pretrained(pretrained_model)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.gradient_checkpointing_disable = model.pretrained_model.gradient_checkpointing_disable\n", "model.gradient_checkpointing_enable = model.pretrained_model.gradient_checkpointing_enable"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_trainable_parameters(model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["GPT-2 tokenizer has a pad token, but it is not eos_token by default. We need to set it to eos_token.<br>\n", "only for this model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tokenizer.pad_token = tokenizer.eos_token"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We then build the PPOTrainer, passing the model, the reference model, the tokenizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ppo_trainer = PPOTrainer(\n", "    config, model, ref_model=None, tokenizer=tokenizer, dataset=dataset, data_collator=collator, optimizer=optimizer\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We then build the sentiment analysis pipeline, passing the model name and the<br>\n", "sentiment analysis pipeline arguments. Let's also make sure to set the device<br>\n", "to the same device as the PPOTrainer."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = ppo_trainer.accelerator.device\n", "if ppo_trainer.accelerator.num_processes == 1:\n", "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n", "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We then define the arguments to pass to the `generate` function. These arguments<br>\n", "are passed to the `generate` function of the PPOTrainer, which is a wrapper around<br>\n", "the `generate` function of the trained model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["generation_kwargs = {\n", "    \"min_length\": -1,\n", "    \"top_k\": 0.0,\n", "    \"top_p\": 1.0,\n", "    \"do_sample\": True,\n", "    \"pad_token_id\": tokenizer.eos_token_id,\n", "    \"eos_token_id\": -1,\n", "}\n", "output_min_length = 4\n", "output_max_length = 16\n", "output_length_sampler = LengthSampler(output_min_length, output_max_length)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n", "    query_tensors = batch[\"input_ids\"]\n", "    model.gradient_checkpointing_disable()\n", "    model.pretrained_model.config.use_cache = True\n", "    # Get response from Causal LM\n", "    response_tensors = []\n", "    for query in query_tensors:\n", "        gen_len = output_length_sampler()\n", "        generation_kwargs[\"max_new_tokens\"] = gen_len\n", "        response = ppo_trainer.generate(query, **generation_kwargs)\n", "        response_tensors.append(response.squeeze()[-gen_len:])\n", "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n\n", "    # Compute sentiment score\n", "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n", "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n", "    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n\n", "    # Run PPO step\n", "    model.gradient_checkpointing_enable()\n", "    model.pretrained_model.config.use_cache = False\n", "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n", "    ppo_trainer.log_stats(stats, batch, rewards)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.push_to_hub(f\"{script_args.model_name}-ppo-sentiment\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}